{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI BootCamp Project - Zaka AI \n",
    "\n",
    "Presented by:\n",
    "    \n",
    "    Rewa Rammal\n",
    "    Elias-Charbel Salameh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"LifeLike Bot Builders\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network model implementation using the Kaggle Animals-10 dataset having 10 classes:\n",
    "\n",
    "cat, dog, squirrel, spider, butterfly, horse, cow, sheep, elephant, chicken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "train_dir = r'C:\\Users\\elias\\OneDrive\\Bureau\\Internships\\Zaka ai\\BootCamp\\Project\\split_dataset\\train'\n",
    "val_dir = r'C:\\Users\\elias\\OneDrive\\Bureau\\Internships\\Zaka ai\\BootCamp\\Project\\split_dataset\\val'\n",
    "data_dir = r'C:\\Users\\elias\\OneDrive\\Bureau\\Internships\\Zaka ai\\BootCamp\\Project\\dataset'\n",
    "test_dir = r'C:\\Users\\elias\\OneDrive\\Bureau\\Internships\\Zaka ai\\BootCamp\\Project\\test_set'\n",
    "        \n",
    "print(\"Setup Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_labels(generator, model, num_images, rows, columns):\n",
    "        # Get the class labels\n",
    "        class_labels = list(generator.class_indices.keys())\n",
    "\n",
    "        # Get a batch of images and their true labels from the generator\n",
    "        images, true_labels = next(generator)\n",
    "        \n",
    "        # Get predictions for the images\n",
    "        predictions = model.predict(images)\n",
    "        predicted_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        true_indices = np.argmax(true_labels, axis=1)\n",
    "        accuracy = np.mean(np.equal(true_indices, np.argmax(predictions, axis=1)))\n",
    "\n",
    "        # Randomly select num_images indices\n",
    "        indices = random.sample(range(len(images)), num_images)\n",
    "        \n",
    "        # Display the images and labels\n",
    "        fig, axes = plt.subplots(rows, columns, figsize=(15, 15))\n",
    "        \n",
    "        for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(images[indices[i]])\n",
    "                true_label = class_labels[np.argmax(true_labels[indices[i]])]\n",
    "                predicted_label = predicted_labels[indices[i]]\n",
    "                \n",
    "                # Check if predicted label matches true label\n",
    "                if true_label == predicted_label:\n",
    "                        title_color = 'green'\n",
    "                else:\n",
    "                        title_color = 'red'\n",
    "                \n",
    "                ax.set_title(f'True Label: {true_label}\\nPredicted Label: {predicted_label}', color=title_color)\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"The accuracy on these 25 images is:\", accuracy)\n",
    "\n",
    "# Function to generate classification report\n",
    "def generate_classification_report(model, generator, class_labels):\n",
    "        predictions = model.predict(generator)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = generator.classes\n",
    "        report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "        print(\"Classification Report:\")\n",
    "        print(\"=====================\")\n",
    "        print(report)\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(model, generator, class_labels):\n",
    "        # Predict the classes\n",
    "        predictions = model.predict(generator)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = generator.classes\n",
    "        class_labels = list(generator.class_indices.keys())\n",
    "\n",
    "        # Generate the confusion matrix\n",
    "        cm = confusion_matrix(true_classes, predicted_classes)\n",
    "        \n",
    "        # Plot the confusion matrix\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        \n",
    "def create_transfer_learning_model(base_model_name, input_shape, num_classes):\n",
    "        if base_model_name == 'VGG16':\n",
    "                base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        elif base_model_name == 'ResNet50':\n",
    "                base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        else:\n",
    "                raise ValueError(\"Base model not supported. Choose 'VGG16' or 'ResNet50'.\")\n",
    "        base_model.trainable = False\n",
    "        model = Sequential([\n",
    "                base_model,\n",
    "                GlobalAveragePooling2D(),\n",
    "                Dense(512, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.5),\n",
    "                Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the directories (each directory represents a class)\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "# Print the classes\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Load a sample image from each class and display it\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, class_name in zip(axes, classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    sample_image_path = os.path.join(class_dir, os.listdir(class_dir)[0])\n",
    "    image = Image.open(sample_image_path)\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(class_name)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the count of images in each class\n",
    "class_counts = {}\n",
    "\n",
    "# Loop through each class directory and count the images\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_dir))\n",
    "    class_counts[class_name] = num_images\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy plotting\n",
    "class_counts_df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Number of Images'])\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Class', y='Number of Images', data=class_counts_df)\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking image dimensions\n",
    "image_shapes = []\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image_shapes.append(image.size)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "image_shapes_df = pd.DataFrame(image_shapes, columns=['Width', 'Height'])\n",
    "\n",
    "# Plot image dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=image_shapes_df, x='Width', kde=True, color='blue', label='Width')\n",
    "sns.histplot(data=image_shapes_df, x='Height', kde=True, color='red', label='Height')\n",
    "plt.title('Image Dimensions Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 264\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(target_size, target_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_data_generator.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(target_size, target_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_data_generator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(target_size, target_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(target_size, target_size, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(1024, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks:\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('other_test.h5', monitor='val_accuracy', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=4, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "print(\"Model initialized and Callbacks defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(train_generator, epochs=50, validation_data=val_generator, \n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot for Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot for Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(model, val_generator, list(val_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(model, val_generator, list(val_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model,test_set, list(test_set.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(model, test_set, list(test_set.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_with_labels(test_set, model, 31, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Other Models using Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape = (target_size, target_size, 3)\n",
    "num_classes = 10\n",
    "\n",
    "vgg16_model = create_transfer_learning_model('VGG16', input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet50_model = create_transfer_learning_model('ResNet50', input_shape, num_classes)\n",
    "resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Transfer Learning Models Created and Compiled.\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=4, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "vgg16_history = vgg16_model.fit(train_generator, epochs=10, validation_data=val_generator, \n",
    "                                callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "\n",
    "vgg16_loss, vgg16_accuracy = vgg16_model.evaluate(val_generator)\n",
    "print(\"VGG16 Validation Loss:\", vgg16_loss)\n",
    "print(\"VGG16 Validation Accuracy:\", vgg16_accuracy)\n",
    "\n",
    "resnet50_history = resnet50_model.fit(train_generator, epochs=10, validation_data=val_generator, \n",
    "                                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "\n",
    "resnet50_loss, resnet50_accuracy = resnet50_model.evaluate(val_generator)\n",
    "print(\"ResNet50 Validation Loss:\", resnet50_loss)\n",
    "print(\"ResNet50 Validation Accuracy:\", resnet50_accuracy)\n",
    "\n",
    "def plot_training_history(history, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{title} - Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{title} - Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(vgg16_history, 'VGG16')\n",
    "plot_training_history(resnet50_history, 'ResNet50')\n",
    "\n",
    "plot_confusion_matrix(vgg16_model, val_generator, list(val_generator.class_indices.keys()))\n",
    "generate_classification_report(vgg16_model, val_generator, list(val_generator.class_indices.keys()))\n",
    "\n",
    "plot_confusion_matrix(resnet50_model, val_generator, list(val_generator.class_indices.keys()))\n",
    "generate_classification_report(resnet50_model, val_generator, list(val_generator.class_indices.keys()))\n",
    "\n",
    "display_images_with_labels(test_set, vgg16_model, 31, 5, 6)\n",
    "display_images_with_labels(test_set, resnet50_model, 31, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded Model Procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('last_test.h5')\n",
    "\n",
    "print(\"Our best model:\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loaded_loss, loaded_accuracy = loaded_model.evaluate(val_generator)\n",
    "print(\"Evaluation Results for the Loaded Model:\")\n",
    "print(\"=========================================\")\n",
    "print(f\"Validation Loss: {loaded_loss}\")\n",
    "print(f\"Validation Accuracy: {loaded_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, val_generator, list(val_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(loaded_model, val_generator, list(val_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, test_set, list(test_set.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(loaded_model, test_set, list(test_set.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_with_labels(test_set, loaded_model, 30, 5, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
